{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vMze11_GZzw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import contractions\n",
        "from unidecode import unidecode\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from autocorrect import Speller\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from string import punctuation\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0d8fSw-HCAy"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"HateSpeechDetection.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5RbUvtGHGOV"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjVhSm6HHHq6"
      },
      "outputs": [],
      "source": [
        "data = data.drop(\"Platform\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9QjNuQzCJ5q"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N99OybJiCPQ1"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0okHx3qCPNS"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgrEwW3WCUUr"
      },
      "outputs": [],
      "source": [
        "data['Hateful'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iBfc1BFTCK9"
      },
      "source": [
        "Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTEmIedQCa4y"
      },
      "outputs": [],
      "source": [
        "hateful_0_count = data[data['Hateful'] == 0]['Comment'].count()\n",
        "hate = data[data['Hateful'] == 1]\n",
        "no_hate = data[data['Hateful'] == 0]\n",
        "hate_oversample = hate.sample(hateful_0_count, replace=True)\n",
        "data_oversampled = pd.concat([no_hate, hate_oversample], axis=0)\n",
        "\n",
        "print('Random over-sampling:')\n",
        "print(data_oversampled['Hateful'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7aEt7nRDDJr"
      },
      "outputs": [],
      "source": [
        "data_oversampled.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxoAJApHTFie"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vwiDDqBJ0NL"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1,2 , figsize=(16,8))\n",
        "text_pos = \" \".join(data['Comment'][data.Hateful == 0])\n",
        "text_neg = \" \".join(data['Comment'][data.Hateful == 1])\n",
        "data_pos = WordCloud(collocations = False, background_color = 'white').generate(text_pos)\n",
        "data_neg = WordCloud(collocations = False, background_color = 'black').generate(text_neg)\n",
        "axs[0].imshow(data_pos, interpolation='bilinear')\n",
        "axs[0].axis('off')\n",
        "axs[0].set_title('Non-Hate Comments')\n",
        "axs[1].imshow(data_neg, interpolation='bilinear')\n",
        "axs[1].axis('off')\n",
        "axs[1].set_title('Hate Comments')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcCP81BYTPq5"
      },
      "source": [
        "Vertical Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8SFrzvn_afl"
      },
      "outputs": [],
      "source": [
        "x =data_oversampled[\"Comment\"].values\n",
        "y =data_oversampled[\"Hateful\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ3XGlRCD5nR"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAUMNV1OD662"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DzHwmHoD6Tl"
      },
      "outputs": [],
      "source": [
        "data_oversampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DowQ4YRCTUC5"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJoeRKE9FrMw"
      },
      "outputs": [],
      "source": [
        "stopword_list = stopwords.words(\"english\")\n",
        "\n",
        "def clean_data(data):\n",
        "    tokens = word_tokenize(data)\n",
        "    clean_text = [word.lower() for word in tokens if (word not in punctuation) and(word.lower() not in stopword_list) and(len(word)>2) and (word.isalpha())]\n",
        "    return clean_text\n",
        "\n",
        "def lemmatization(data1):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    final_data1 = []\n",
        "    for word in data1:\n",
        "        lemmatized_word = lemmatizer.lemmatize(word)\n",
        "        final_data1.append(lemmatized_word)\n",
        "    return \" \".join(final_data1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgTtakgxDhpu"
      },
      "outputs": [],
      "source": [
        "data_oversampled[\"Comment\"] = data_oversampled[\"Comment\"].apply(clean_data)\n",
        "data_oversampled[\"Comment\"] = data_oversampled[\"Comment\"].apply(lemmatization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iq7-T0IGAph"
      },
      "outputs": [],
      "source": [
        "data_oversampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaegUoVVG2dc"
      },
      "source": [
        "Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWUg7hmZ-Cy5"
      },
      "outputs": [],
      "source": [
        "tfidf=TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQObTakB-b5w"
      },
      "outputs": [],
      "source": [
        "x=tfidf.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8o1OlVDDyGV"
      },
      "outputs": [],
      "source": [
        "x=x.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiCO5flw-tdK"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xFkmkiqG69h"
      },
      "source": [
        "Horizontal Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaONZKK4-mXH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmTRVduDJdcZ"
      },
      "outputs": [],
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.2, random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY74_LXoJ1np"
      },
      "outputs": [],
      "source": [
        "print(\"xtrain: \", xtrain.shape)\n",
        "print(\"ytrain: \", ytrain.shape)\n",
        "print(\"xtest: \", xtest.shape)\n",
        "print(\"ytest: \", ytest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lr3G5AkTZDk"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsD_lIb7KGD0"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ksaHQqKKGJM"
      },
      "outputs": [],
      "source": [
        "model1 = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "545iNb-5KGPz"
      },
      "outputs": [],
      "source": [
        "model1.fit(xtrain,ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7hbqDdiqO8Y"
      },
      "outputs": [],
      "source": [
        "predict1=model1.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OurtbceTiq6"
      },
      "outputs": [],
      "source": [
        "accuracy1 = accuracy_score(ytest,predict1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0ofOyWjUg5c"
      },
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, predict1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM3XDIM5qc0w"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy of Decision Tree :\", accuracy1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b02dhNge8dfx"
      },
      "outputs": [],
      "source": [
        "test_data = \"Desecrate men by making them gay/trannies, and women by making them abort children and become psycho feminist cunts etc\"\n",
        "data = tfidf.transform([test_data]).toarray()\n",
        "print(model1.predict(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILW5A8ffAXHX"
      },
      "outputs": [],
      "source": [
        "test_data = \"Saudi Arabia has tv? I thought they just watched public rapes for entertainment\"\n",
        "data = tfidf.transform([test_data]).toarray()\n",
        "print(model1.predict(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-cmG6qETzlH"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqrqa9JuAKpn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y15XL8bXAjcH"
      },
      "outputs": [],
      "source": [
        "model2=LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDJ8xuVQAm0m"
      },
      "outputs": [],
      "source": [
        "model2.fit(xtrain,ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emMb9u53ApsH"
      },
      "outputs": [],
      "source": [
        "predict2=model2.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_qc_4F0T5Tw"
      },
      "outputs": [],
      "source": [
        "accuracy2 = accuracy_score(ytest,predict2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1yoHUeXBCl-"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy of Logistic Regression :\",accuracy2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPwB5s_wUcpL"
      },
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, predict2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uABl8ICPUBSt"
      },
      "source": [
        "Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5rwfmJdJceh"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3d5375a"
      },
      "outputs": [],
      "source": [
        "model3= BernoulliNB(binarize= 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b50711ae"
      },
      "outputs": [],
      "source": [
        "model3.fit(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1598fe8"
      },
      "outputs": [],
      "source": [
        "predict3= model3.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1Gxes4mUF76"
      },
      "outputs": [],
      "source": [
        "accuracy3 = accuracy_score(ytest, predict3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e82f9550"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy of Bernouli Naive Bayes :\",accuracy_score(ytest,predict3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76351c03"
      },
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, predict3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6ggy1q8KMvD"
      },
      "outputs": [],
      "source": [
        "test_data = \"you are sweet\"\n",
        "df = tfidf.transform([test_data]).toarray()\n",
        "print(model3.predict(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa0Sbx42Ul84"
      },
      "source": [
        "Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aL0Is-j1lgyp"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKzD7XxcmXzB"
      },
      "outputs": [],
      "source": [
        "model4 = RandomForestClassifier(n_estimators = 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhiQgyETmaUp"
      },
      "outputs": [],
      "source": [
        "model4.fit(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGzL2TlWme45"
      },
      "outputs": [],
      "source": [
        "predict4 = model4.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GZ6HHwemlqx"
      },
      "outputs": [],
      "source": [
        "accuracy4 = accuracy_score(ytest, predict4)\n",
        "print(\"Accuracy Score:\", accuracy4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEh56AoXNM0c"
      },
      "outputs": [],
      "source": [
        "test_data = \"The Irony of calling the Asian guy/girl a monkey is just too funny to be true.\"\n",
        "df = tfidf.transform([test_data]).toarray()\n",
        "print(model4.predict(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3SOPxw_NT7H"
      },
      "outputs": [],
      "source": [
        "test_data = \"you are good\"\n",
        "df = tfidf.transform([test_data]).toarray()\n",
        "print(model4.predict(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3uUIas_U3MO"
      },
      "source": [
        "Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3j8cvRkPBJi"
      },
      "outputs": [],
      "source": [
        "scaler=MinMaxScaler() #normalizing\n",
        "xtrain_scaled = scaler.fit_transform(xtrain)\n",
        "xtest_scaled = scaler.transform(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA2gqZkNPkes"
      },
      "outputs": [],
      "source": [
        "lr_list=[0.05,0.075,0.1,0.25,0.5,0.75,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLU1VC8dPrH6"
      },
      "outputs": [],
      "source": [
        "for learning_rate in lr_list:\n",
        "  model5 = GradientBoostingClassifier(n_estimators=100, learning_rate=learning_rate,max_features=2,max_depth=2,random_state=0)\n",
        "  model5.fit(xtrain_scaled,ytrain)\n",
        "  predict5 = model5.predict(xtest_scaled)\n",
        "\n",
        "  print(\"Learning Rate: \", learning_rate)\n",
        "  print(\"Accuracy_score (training): {0:.3f}\".format(model5.score(xtrain_scaled,ytrain)))\n",
        "  print(\"Accuracy_score (testing): {0:.3f}\".format(model5.score(xtest_scaled,ytest)))\n",
        "  #with which learning rate best score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv8xX01kaory"
      },
      "outputs": [],
      "source": [
        "model5 = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.25,max_features=2,max_depth=2,random_state=0)\n",
        "model5.fit(xtrain_scaled,ytrain)\n",
        "predict5 = model5.predict(xtest_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbhiK_VBazgq"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy Score of Gradient Boosting: \", model5.score(xtest_scaled, ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JSlWIF7SE-0"
      },
      "outputs": [],
      "source": [
        "test_data = \"The Irony of calling the Asian guy/girl a monkey is just too funny to be true. \"\n",
        "df = tfidf.transform([test_data]).toarray()\n",
        "print(model5.predict(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TdBS9k3X8K7"
      },
      "source": [
        "Ada Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMeHTLb7m1gc"
      },
      "outputs": [],
      "source": [
        "model6=AdaBoostClassifier(n_estimators=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpFVR5MUm8Vs"
      },
      "outputs": [],
      "source": [
        "model6.get_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuRYvOuom-uM"
      },
      "outputs": [],
      "source": [
        "model6.fit(xtrain_scaled,ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7F7vKStnBak"
      },
      "outputs": [],
      "source": [
        "y_pred=model6.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujPx_tP8Q9TB"
      },
      "outputs": [],
      "source": [
        "print(accuracy_score(ytest,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScYetZZWYBnk"
      },
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Mq3XRSOWi-"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDkW6wg9RKHZ"
      },
      "outputs": [],
      "source": [
        "xgb_classifier = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "xgb_classifier.fit(xtrain, ytrain)\n",
        "y_pred = xgb_classifier.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmEgI8tRPAsm"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy Score XGBoost: \", accuracy_score(ytest, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMNJrQF6YGWs"
      },
      "source": [
        "Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAiuDrCSSB9e"
      },
      "outputs": [],
      "source": [
        "from numpy import mean\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import StackingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZtuc8EFFLWa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_stacking():\n",
        "  level0=list()\n",
        "  level0.append(('knn',KNeighborsRegressor()))\n",
        "  level0.append(('cart',DecisionTreeRegressor()))\n",
        "  level0.append(('svm',SVR()))\n",
        "  level1=LinearRegression()\n",
        "  model=StackingRegressor(estimators=level0,final_estimator=level1) # to create main model\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBOJYWqlGCBL"
      },
      "outputs": [],
      "source": [
        "#retrieving models\n",
        "def get_model():\n",
        "  models=dict()\n",
        "  # models['knn']=KNeighborsRegressor()\n",
        "  # models['cart']=DecisionTreeRegressor()\n",
        "  # models['svm']=SVR()\n",
        "  models['stacking']=get_stacking()\n",
        "  return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbDRJMZIG4zX"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model,x,y):\n",
        "  cv=RepeatedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
        "  scores=cross_val_score(model,x,y,scoring='neg_mean_absolute_error',cv=cv)\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI4LMoPaHVYz"
      },
      "outputs": [],
      "source": [
        "models=get_model()\n",
        "results,names=list(),list()\n",
        "for name,model in models.items():\n",
        "  scores=evaluate_model(model,x,y)\n",
        "  results.append(scores)\n",
        "  names.append(model)\n",
        "  print(name,mean(scores))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl8RKDW6S5c3"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy of Decision Tree :\",accuracy_score(ytest,predict1))\n",
        "print(\"Accuracy of Logisitc Regression :\",accuracy)\n",
        "print(\"Accuracy of Naives Bayes:\",accuracy_score(ytest,prediction3))\n",
        "print(\"Accuracy of Random Forest :\",accuracy2)\n",
        "print(\"Accuracy of Ada Bosting :\",metrics.accuracy_score(ytest,y_pred))\n",
        "print(\"Accuracy of Stacking :\",accuracy_score(ytest,predict1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odwHneJcRdCC"
      },
      "source": [
        "Evaluating Accuracy a Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjvMO60LlsSd"
      },
      "outputs": [],
      "source": [
        "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [acc,acc1,acc2,acc3]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Algorithm Comparision')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Qnddjq5YT56"
      },
      "outputs": [],
      "source": [
        "plt.plot(fpr_np,tpr_np,label=\"Naive Bayes, AUC=\"+str(auc_np))\n",
        "plt.plot(fpr_dt,tpr_dt,label=\"Decision Tree, AUC=\"+str(auc_dt))\n",
        "plt.plot(fpr_knn,tpr_knn,label=\"K-Nearest Neighbors, AUC=\"+str(auc_knn))\n",
        "plt.plot(fpr_lr,tpr_lr,label=\"Logistic Regression, AUC=\"+str(auc_lr))\n",
        "plt.plot(fpr_rf,tpr_rf,label=\"Random Forest, AUC=\"+str(auc_rf))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "\n",
        "#add legend\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}